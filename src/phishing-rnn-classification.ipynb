{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch: Classifying Phishing websites with an Atribute-Level RNN\n",
    "\n",
    "To detect whether a given URL has a high probability of being a Phishing Website, we make use of a Recurrent Neural Network (RNN) as an attribute-level classifier for Website URLs.\n",
    "\n",
    "The RNN will read each URL as a series of attributes, outputting a prediction and \"hidden state\" at each step, and feeds its previous hidden state into each next step. We will take the final prediction to be the output, i.e. which class the URL belongs to: Phishing Website, or Non-Phishing Website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the Data\n",
    "\n",
    "For this network, we used a CSV file containing the Phishing Website URLs that were split into attributes. The data can be downloaded separately at https://phishtank.com/. \n",
    "\n",
    "Specifically, we used 10,988 URLs from the PhishTank Database (As of March 31, 2022), confirmed to be either a Phishing Website URL or a Non-Phishing Website URL, in order to train our network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import random\n",
    "\n",
    "# Use Pandas to read the CSV data file\n",
    "data_file = pd.read_csv('../data/data.csv')\n",
    "data = data_file.values.tolist()\n",
    "\n",
    "# Randomly shuffle the data\n",
    "random.shuffle(data)\n",
    "\n",
    "# Set class labels\n",
    "labels = [\"Non-Phishing Website\", \"Phishing Website\"]\n",
    "labels_tensor = torch.LongTensor([0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Data into Tensors\n",
    "\n",
    "We first split the data into Training Data and Test Data. We allocate 2000 of the examples to be Test Data.\n",
    "\n",
    "Then, we turn each of the obtained data and the corresponding labels into tensors. Hence, each URL will correspond to a single 1 x 16 Tensor, where 16 corresponds to the 16 attributes that each URL has.\n",
    "\n",
    "Each URL has a label of either 1 (Phishing Website) or 0 (Non-Phishing Website)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8988, 16, 1, 16])\n",
      "torch.Size([8988])\n",
      "torch.Size([2000, 16, 1, 16])\n",
      "torch.Size([2000])\n",
      "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 1.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 1., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 1.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0., 0., 0.,  ..., 1., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 1., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 1.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 1.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 1., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 1.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 1., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 1.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 1., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 1., 0.]],\n",
      "\n",
      "         [[0., 0., 0.,  ..., 0., 0., 0.]]]])\n"
     ]
    }
   ],
   "source": [
    "# Set training data and test data sizes\n",
    "data_size = len(data)\n",
    "test_data_size = 2000\n",
    "training_data_size = data_size - test_data_size\n",
    "\n",
    "# Set metadata for our RNN\n",
    "num_of_attributes = 16\n",
    "hidden_size = 128\n",
    "num_of_labels = 2\n",
    "\n",
    "# Extract out training data and test data\n",
    "training_data = torch.Tensor(training_data_size, 16, 1, 16)\n",
    "test_data = torch.Tensor(test_data_size, 16, 1, 16)\n",
    "\n",
    "training_data_domain = []\n",
    "test_data_domain = []\n",
    "training_label = torch.LongTensor(training_data_size)\n",
    "test_label = torch.LongTensor(test_data_size)\n",
    "\n",
    "for i in range(training_data_size):\n",
    "    training_data_domain.append(data[i][0])\n",
    "    \n",
    "    new_data = data[i][1:-1]\n",
    "    new_tensor = torch.zeros(16, 1, 16)\n",
    "    for idx, att in enumerate(new_data):\n",
    "        new_tensor[idx][0][idx] = att\n",
    "    training_data[i] = new_tensor\n",
    "    training_label[i] = data[i][-1]\n",
    "\n",
    "for j in range(test_data_size):\n",
    "    test_data_domain.append(data[j+training_data_size][0])\n",
    "    \n",
    "    new_data = data[j+training_data_size][1:-1]\n",
    "    new_tensor = torch.zeros(16, 1, 16)\n",
    "    for idx, att in enumerate(new_data):\n",
    "        new_tensor[idx][0][idx] = att\n",
    "    test_data[j] = new_tensor    \n",
    "    test_label[j] = data[j+training_data_size][-1]\n",
    "    \n",
    "# Convert the data into PyTorch Tensors\n",
    "print(training_data.size())\n",
    "print(training_label.size())\n",
    "print(test_data.size())\n",
    "print(test_label.size())\n",
    "print(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Network\n",
    "\n",
    "This RNN has been largely taken from [the PyTorch for Torch users tutorial](https://github.com/pytorch/tutorials/blob/master/Introduction%20to%20PyTorch%20for%20former%20Torchies.ipynb). It is just 2 linear layers which operate on an input and hidden state, with a LogSoftmax layer after the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        # Define the input, hidden, and output sizes of the network\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        # Define the two linear layers, with Softmax as the non-linear layer\n",
    "        self.input_to_hidden_layer = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.input_to_output_layer = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim = 1)\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "\n",
    "        # Combine the input and the hidden layer into a single Tensor, for the training process\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        \n",
    "        # Run the Tensor through the network\n",
    "        hidden = self.input_to_hidden_layer(combined)\n",
    "        output = self.input_to_output_layer(combined)\n",
    "        output = self.softmax(output)\n",
    "        \n",
    "        # Return the results of the network\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return Variable(torch.zeros(1, self.hidden_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually testing the network\n",
    "\n",
    "With our custom `RNN` class defined, we can create a new instance, `net`.\n",
    "\n",
    "To run a step of this network, we can pass in an input (in this case, the features for the first URL in our att_set) and a previous hidden state (Initialized as zeros at first). We will get back the output (probability of each label) and a next hidden state (which we keep for the next step).\n",
    "\n",
    "As you can see the output is a `<1 x num_of_labels>` Tensor, where every item is the likelihood of the label (higher is more likely)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output size = torch.Size([1, 2])\n",
      "tensor([[-0.7410, -0.6475]], grad_fn=<LogSoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "net = RNN(num_of_attributes, hidden_size, num_of_labels)\n",
    "\n",
    "ex_input = training_data[0]\n",
    "ex_hidden = net.init_hidden()\n",
    "\n",
    "ex_output, ex_next_hidden = net(ex_input[0], ex_hidden)\n",
    "print('output size =', ex_output.size())\n",
    "print(ex_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing for Training\n",
    "\n",
    "Before going into training we should make a few helper functions. The first is to interpret the output of the network, which we know to be a likelihood of each label. We can use `Tensor.topk` to get the index of the greatest value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1]])\n",
      "Prediction: Phishing Website\n"
     ]
    }
   ],
   "source": [
    "def category(output):\n",
    "    \n",
    "    # Tensor out of Variable with .data\n",
    "    top_n, top_i = output.data.topk(1)\n",
    "    print(top_i)\n",
    "    category_i = top_i[0][0]\n",
    "    return \"Prediction: \" + labels[category_i]\n",
    "\n",
    "print(category(ex_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also want a quick way to get a training example (A set of attributes and its true label) from a given index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Attribute = tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 2., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]) \n",
      "Label = Non-Phishing Website \n",
      "\n",
      "\n",
      "Attribute = tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]]]) \n",
      "Label = Non-Phishing Website \n",
      "\n",
      "\n",
      "Attribute = tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]) \n",
      "Label = Non-Phishing Website \n",
      "\n",
      "\n",
      "Attribute = tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]) \n",
      "Label = Phishing Website \n",
      "\n",
      "\n",
      "Attribute = tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]) \n",
      "Label = Phishing Website \n",
      "\n",
      "\n",
      "Attribute = tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 3., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]) \n",
      "Label = Non-Phishing Website \n",
      "\n",
      "\n",
      "Attribute = tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]) \n",
      "Label = Non-Phishing Website \n",
      "\n",
      "\n",
      "Attribute = tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]) \n",
      "Label = Non-Phishing Website \n",
      "\n",
      "\n",
      "Attribute = tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]) \n",
      "Label = Phishing Website \n",
      "\n",
      "\n",
      "Attribute = tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]) \n",
      "Label = Phishing Website \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_training_example(index, train=True):\n",
    "    \n",
    "    if (train):\n",
    "        # Use the random integer to select a particular training example\n",
    "        attribute_tensor = training_data[index]\n",
    "        label_tensor = torch.Tensor([training_label[index]]).long()\n",
    "\n",
    "    else:\n",
    "        # Use the random integer to select a particular training example\n",
    "        attribute_tensor = test_data[index]\n",
    "        label_tensor = torch.Tensor([test_label[index]]).long()\n",
    "    \n",
    "    # Return the Attribute, Label, and their corresponding Tensors\n",
    "    return attribute_tensor, label_tensor\n",
    "    \n",
    "for i in range(10):\n",
    "    attribute_tensor, label_tensor = get_training_example(i)\n",
    "    print('\\nAttribute =', attribute_tensor, '\\nLabel =', labels[label_tensor.item()], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may also define a handy function to get the error of the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error(scores, labels):\n",
    "\n",
    "    batch_size = scores.size(0)\n",
    "    predicted_labels = scores.argmax(dim = 1)\n",
    "    indicator = (predicted_labels == labels)\n",
    "    num_of_matches = indicator.sum()\n",
    "    \n",
    "    return 1 - num_of_matches.float() / batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And also a function to get the accuracy of the network as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(scores, labels):\n",
    "    \n",
    "    batch_size = scores.size(0)\n",
    "    predicted_labels = scores.argmax(dim=1)\n",
    "    indicator = (predicted_labels == labels)\n",
    "    num_of_matches = indicator.sum()\n",
    "    return 100 * num_of_matches.float() / batch_size  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we may define a function to evaluate our network on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_on_test_data():\n",
    "\n",
    "    running_accuracy = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for i in range(0, test_data_size):\n",
    "\n",
    "        hidden = net.init_hidden()\n",
    "        \n",
    "        attribute_tensor, label_tensor = get_training_example(shuffled_indices_test[i].item(), False)\n",
    "        \n",
    "        for i in range(num_of_attributes):\n",
    "            output, hidden = net(attribute_tensor[i], hidden)\n",
    "        \n",
    "        # Compute some stats\n",
    "        accuracy = get_accuracy(output.detach(), label_tensor)\n",
    "        running_accuracy += accuracy.item()\n",
    "        \n",
    "        num_batches += 1\n",
    "        \n",
    "    total_accuracy = running_accuracy / num_batches\n",
    "    print('Test Accuracy =', total_accuracy, 'percent')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the Network\n",
    "\n",
    "Now all it takes to train this network is show it a bunch of examples, have it make guesses, and tell it if it's wrong.\n",
    "\n",
    "For our loss function, [`nn.NLLLoss`](http://pytorch.org/docs/nn.html#nllloss) is appropriate, since the last layer of the RNN is `nn.LogSoftmax`. We will also use a Learning Rate of 0.005."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "learning_rate = 0.005"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train our network for a total of 100 epochs. Each epoch will train our network on all of the training data, in a randomised order.\n",
    "\n",
    "Within each epoch, we will pass in the individual attribute tensors of a single training example (16 in total) one at a time. This will be done for all examples (around ~8000 times).\n",
    "\n",
    "After every 10 epoch, we will test our partially-trained network on the test data and have it output the accuracy rate on the test data.\n",
    "\n",
    "The average accuracy of this architecture, with the set that was initially used to train and test, is around 87 ~ 88%. Results may vary with different parameters and data set used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch = 0 \n",
      "Elapsed Time = 9.648565530776978 \n",
      "Loss = 0.6841134036056826 \n",
      "Error = 43.958611481975964 \n",
      "Learning Rate = 0.005 \n",
      "\n",
      "Test Accuracy = 59.8 percent\n",
      "\n",
      "Epoch = 10 \n",
      "Elapsed Time = 106.57540845870972 \n",
      "Loss = 0.2980557216001938 \n",
      "Error = 11.504227859368047 \n",
      "Learning Rate = 0.005 \n",
      "\n",
      "Test Accuracy = 86.95 percent\n",
      "\n",
      "Epoch = 20 \n",
      "Elapsed Time = 203.94273114204407 \n",
      "Loss = 0.29878498092486505 \n",
      "Error = 11.426346239430352 \n",
      "Learning Rate = 0.005 \n",
      "\n",
      "Test Accuracy = 86.95 percent\n",
      "\n",
      "Epoch = 30 \n",
      "Elapsed Time = 302.186320066452 \n",
      "Loss = 0.2957939164415235 \n",
      "Error = 11.481975967957277 \n",
      "Learning Rate = 0.005 \n",
      "\n",
      "Test Accuracy = 87.1 percent\n",
      "\n",
      "Epoch = 40 \n",
      "Elapsed Time = 400.8748769760132 \n",
      "Loss = 0.2956726012785223 \n",
      "Error = 11.470850022251891 \n",
      "Learning Rate = 0.005 \n",
      "\n",
      "Test Accuracy = 87.1 percent\n",
      "\n",
      "Epoch = 50 \n",
      "Elapsed Time = 500.94018268585205 \n",
      "Loss = 0.2945947323390529 \n",
      "Error = 11.359590565198042 \n",
      "Learning Rate = 0.005 \n",
      "\n",
      "Test Accuracy = 87.1 percent\n",
      "\n",
      "Epoch = 60 \n",
      "Elapsed Time = 599.52343583107 \n",
      "Loss = 0.2952382060821226 \n",
      "Error = 11.381842456608812 \n",
      "Learning Rate = 0.005 \n",
      "\n",
      "Test Accuracy = 87.1 percent\n",
      "\n",
      "Epoch = 70 \n",
      "Elapsed Time = 698.4102954864502 \n",
      "Loss = 0.29431456490655317 \n",
      "Error = 11.404094348019582 \n",
      "Learning Rate = 0.005 \n",
      "\n",
      "Test Accuracy = 86.4 percent\n",
      "\n",
      "Epoch = 80 \n",
      "Elapsed Time = 796.6539301872253 \n",
      "Loss = 0.29348013102472814 \n",
      "Error = 11.392968402314196 \n",
      "Learning Rate = 0.005 \n",
      "\n",
      "Test Accuracy = 87.1 percent\n",
      "\n",
      "Epoch = 90 \n",
      "Elapsed Time = 896.3282878398895 \n",
      "Loss = 0.2978631571129156 \n",
      "Error = 11.526479750778815 \n",
      "Learning Rate = 0.005 \n",
      "\n",
      "Test Accuracy = 86.95 percent\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "# Initialise the net\n",
    "net = RNN(num_of_attributes, hidden_size, num_of_labels)\n",
    "num_of_epochs = 100\n",
    "\n",
    "# Keep track of losses for plotting\n",
    "current_loss = 0\n",
    "all_losses = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Start the training process\n",
    "for epoch in range(num_of_epochs):\n",
    "    \n",
    "    # create a new optimizer at the beginning of each epoch: give the current learning rate.  \n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr = learning_rate)\n",
    "    \n",
    "    running_loss = 0\n",
    "    running_error = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    shuffled_indices_training = torch.randperm(training_data_size)\n",
    "    shuffled_indices_test = torch.randperm(test_data_size)\n",
    "    \n",
    "    for count in range(0, training_data_size):\n",
    "        \n",
    "        # Forward and Backward Passes    \n",
    "        optimizer.zero_grad()\n",
    "        hidden = net.init_hidden()\n",
    "        attribute_tensor, label_tensor = get_training_example(shuffled_indices_training[count].item(), True)\n",
    "\n",
    "        for i in range(num_of_attributes):\n",
    "            output, hidden = net(attribute_tensor[i], hidden)\n",
    "            \n",
    "        loss = criterion(output, label_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Compute some stats\n",
    "        running_loss += loss.detach().item()\n",
    "        error = get_error(output.detach(), label_tensor)\n",
    "        running_error += error.item()\n",
    "        num_batches += 1\n",
    "    \n",
    "    # Once the epoch is finished, we divide the \"running quantities\" by the number of batches\n",
    "    total_loss = running_loss / num_batches\n",
    "    total_error = running_error / num_batches\n",
    "    elapsed_time = time.time() - start\n",
    "    \n",
    "    # Every 10 epoch, we display the stats and compute the error rate on the test set  \n",
    "    if epoch % 10 == 0 : \n",
    "        print('\\nEpoch =', epoch, '\\nElapsed Time =', elapsed_time, '\\nLoss =', total_loss, '\\nError =', total_error * 100,'\\nLearning Rate =', learning_rate, '\\n')\n",
    "        evaluate_on_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Raw Cell Format",
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
